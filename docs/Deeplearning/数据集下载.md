# Dataset Download links

>  Some computer vision datasets links. Only using for academic research. 

# GAPartNet Dataset


GAPartNet Dataset Download

**GAPartNet Dataset** has been released here ([https://drive.google.com/drive/folders/1Qr52lKwfNAJkwRJK1LOryccD_RjJvtMA?usp=sharing](https://www.google.com/url?q=https://drive.google.com/drive/folders/1Qr52lKwfNAJkwRJK1LOryccD_RjJvtMA?usp%3Dsharing&sa=D&source=editors&ust=1715697519789415&usg=AOvVaw0StSK5ymhfS_7Nz_0vQ36Y)), including Object & Part Assets and Annotations, Rendered PointCloud Data and our Pre-trained Checkpoint.

Please cite our paper if you use our dataset.

```
@article{geng2022gapartnet,  
    title={GAPartNet: Cross-Category Domain-Generalizable Object Perception and Manipulation via Generalizable and Actionable Parts},  
    author={Geng, Haoran and Xu, Helin and Zhao, Chengyang and Xu, Chao and Yi, Li and Huang, Siyuan and Wang, He},  
    journal={arXiv preprint arXiv:2211.05272},  
    year={2022}
}
```

# Scannet

# Mattport3D 


# **MVImgNet**

Download Link: [https://cuhko365-my.sharepoint.com/:f:/g/personal/gaplab_cuhk_edu_cn/EqsPqFli6rNOuL5vvhgCCZMBlJQNmM26uLcjtPGek2h8Nw](https://www.google.com/url?q=https://cuhko365-my.sharepoint.com/:f:/g/personal/gaplab_cuhk_edu_cn/EqsPqFli6rNOuL5vvhgCCZMBlJQNmM26uLcjtPGek2h8Nw&sa=D&source=editors&ust=1703488537555204&usg=AOvVaw0XPulIubL6aOdhn_xJD_pG)

Password: CUHKSZ-bwyl


# LaMAR dataset

You may find the data following this link: [https://cvg-data.inf.ethz.ch/lamar/](https://www.google.com/url?q=https://cvg-data.inf.ethz.ch/lamar/&sa=D&source=editors&ust=1705987747883214&usg=AOvVaw0J4mHqiUE37rZ4Vnuxyqt4)

# EmbodiedScan

Google Drive: https://drive.google.com/file/d/1eJOi8dFPcEgKJ5suXwQPTBh6CicTq5JF/view?usp=sharing 

Baidu Drive: https://pan.baidu.com/s/1lHda_efD2pC8TSGr2VDVsQ?pwd=bizi 

 
Please follow the guide provided at [EmbodiedScan/data at main ãƒ» OpenRobotLab/EmbodiedScan](https://github.com/OpenRobotLab/EmbodiedScan/tree/main/data) to organize the raw data and our annotation files. Feel free to post your questions in the github issue and we will try our best to address them ASAP. 

 
